{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f734a49",
   "metadata": {},
   "source": [
    "Problem 4a: You are given a well-known data set for pattern classification on three types of iris, iris.data, iris.names. Partition your data into roughly 80% training set and 20% test set. Using logistic regression to classify which class of iris plant given the different attributes. What is Etrain? What is the test error Etest? Which one is bigger? What did you expect?\n",
    "\n",
    "Comments:\n",
    "\n",
    "After using the logistic function, the training error was found to be 1.7% while the testing error is 3.3%. The testing error is larger than the training error and this is to be expected as the data is multi-class, the test set is small in comparrison to the training set, and the learned theta values are being evaluated on unseen data which naturally causes an increase in error in comparison to the common data seen in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1465e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.01666666666666672\n",
      "Testing Error: 0.033333333333333326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencerkerkau/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Imported Libraries for splitting data, pandas for loading data, and numpy for basic math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in data from the csv file\n",
    "Iris_Data = pd.read_csv('/Users/spencerkerkau/Desktop/EE 445 HW1 Dataset/iris.data.txt', \n",
    "                   names=['sepal length in cm', 'sepal width in cm', 'petal length in cm', 'petal width in cm',\n",
    "                          'Class'])\n",
    "\n",
    "# Selecting the continuous features as per the attribute information\n",
    "features = ['sepal length in cm', 'sepal width in cm', 'petal length in cm', 'petal width in cm']\n",
    "target = 'Class'\n",
    "\n",
    "# Split the data into features and target\n",
    "X = Iris_Data[features]\n",
    "y = Iris_Data[target]\n",
    "\n",
    "# Split the dataset into training set and test set with 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "\n",
    "# Pad a column of ones to the feature lists\n",
    "X_train_with_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test_with_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "''' I COULDN'T FIGURE OUT EXACTLY HOW TO IMPLEMENT THE LOGISTIC REGRESSION SO I PUT THE STEPS I\n",
    "BELIEVE NEED TO BE TAKEN TO COMPLETE THE PROBLEM. I THEN SHOW THE RESULTS USING THE SCIKIT LIBRARY'''\n",
    "\n",
    "# Create a column vector of exp(Zm) where m is the number of class types\n",
    "''' theta_m = Z_m = transpose(theta_m) dot x '''\n",
    "\n",
    "# Call the softmax function\n",
    "''' softmax(z) = exp(transpose(theta_m.dot(x))) / sum(exp(transpose(theta_j).dot(x))) '''\n",
    "\n",
    "# Minimize the cost function for the cross-entropy for multiclass problem\n",
    "''' J(theta) = 1/n sum(-transpose(theta_yi.dot(xi)) + natural_log(sum(exp(transpose(theta_j).dot(xi))))) '''\n",
    "\n",
    "# Minimizing the cost function gives us the best thetas to evaluate the testing data\n",
    "\n",
    "# I couldnt fully figure out how to implement this so I put code that calls the scikit library\n",
    "# to find the logistic regression training and testing error.\n",
    "\n",
    "# Call the logistic function from scikit\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "# Insert the training data into the model to find theta values\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "# Find Training error\n",
    "Training_Error = 1 - logisticRegr.score(X_train, y_train)\n",
    "\n",
    "# Find Testing error\n",
    "Test_Error = 1 - logisticRegr.score(X_test, y_test)\n",
    "\n",
    "print('Training Error: ' + str(Training_Error))\n",
    "print('Testing Error: ' + str(Test_Error))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
