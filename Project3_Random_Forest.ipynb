{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd  # type: ignore\n",
    "\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "from imblearn.combine import SMOTETomek # type: ignore\n",
    "from imblearn.under_sampling import TomekLinks # type: ignore\n",
    "\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from sklearn.preprocessing import StandardScaler # type: ignore\n",
    "\n",
    "from sklearn.metrics import f1_score # type: ignore\n",
    "\n",
    "import optuna # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_sm: 96.83 % of the dataset\n",
      "asd_sm: 1.43 % of the dataset\n",
      "kd_sm: 0.64 % of the dataset\n",
      "rhd_sm: 1.1 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "asd_sm = pd.read_csv('asd_sm.csv')\n",
    "kd_sm = pd.read_csv('kd_sm.csv')\n",
    "normal_sm = pd.read_csv('normal_sm.csv')\n",
    "rhd_sm = pd.read_csv('rhd_sm.csv')\n",
    "\n",
    "normal_sm['state'] = 0\n",
    "asd_sm['state'] = 1\n",
    "kd_sm['state'] = 2\n",
    "rhd_sm['state'] = 3\n",
    "\n",
    "combined_df = pd.concat([normal_sm, asd_sm, kd_sm, rhd_sm], axis=0)\n",
    "\n",
    "print('normal_sm:', round(combined_df['state'].value_counts()[0]/len(combined_df) * 100,2), '% of the dataset')\n",
    "print('asd_sm:', round(combined_df['state'].value_counts()[1]/len(combined_df) * 100,2), '% of the dataset')\n",
    "print('kd_sm:', round(combined_df['state'].value_counts()[2]/len(combined_df) * 100,2), '% of the dataset')\n",
    "print('rhd_sm:', round(combined_df['state'].value_counts()[3]/len(combined_df) * 100,2), '% of the dataset')\n",
    "\n",
    "raw_data = combined_df.copy()\n",
    "raw_data.drop_duplicates(inplace=True)\n",
    "\n",
    "X = raw_data.drop('state', axis=1)\n",
    "y = raw_data['state']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier with no data feature scaling or data imbalance handling\n",
      "--------------------------------------------------\n",
      "Random Forest Classifier: Training F1 Score: 0.4536402836268748 | Validation F1 Score: 0.3949774123570443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_RFC = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "clf_RFC.fit(X_train, y_train)\n",
    "training_output = clf_RFC.predict(X_train)\n",
    "training_f1 = f1_score(y_train, training_output, average='macro')\n",
    "\n",
    "Validation_Output = clf_RFC.predict(X_validation)\n",
    "Validation_f1 = f1_score(y_validation, Validation_Output, average='macro')\n",
    "\n",
    "print('Random Forest Classifier with no data feature scaling or data imbalance handling')\n",
    "print('-' * 50)\n",
    "print(f'Random Forest Classifier: Training F1 Score: {training_f1} | Validation F1 Score: {Validation_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set F1 Score: 0.24600159052752496\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('future.no_silent_downcasting', True)\n",
    "# Test_Set = pd.read_csv('test_all.csv').copy()\n",
    "\n",
    "# X = Test_Set.drop('state', axis=1)\n",
    "# y = Test_Set['state']\n",
    "\n",
    "# mapping = {\n",
    "#     'normal': 0,\n",
    "#     'asd': 1,\n",
    "#     'kd': 2,\n",
    "#     'rhd': 3\n",
    "# }\n",
    "\n",
    "# y = y.replace(mapping)\n",
    "# y.fillna(0, inplace=True)\n",
    "# y = y.astype(int)\n",
    "\n",
    "# def Standard_Scaler (df, col_names):\n",
    "#     features = df[col_names]\n",
    "#     scaler = StandardScaler().fit(features.values)\n",
    "#     features = scaler.transform(features.values)\n",
    "#     df[col_names] = features\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# col_names = X.columns\n",
    "\n",
    "# X_test = Standard_Scaler(X, col_names)\n",
    "\n",
    "# # Assuming clf_GBC is already trained and available\n",
    "# test_output = clf_RFC.predict(X_test)\n",
    "# test_f1 = f1_score(y, test_output, average='macro')\n",
    "\n",
    "# print(f'Test Set F1 Score: {test_f1}')\n",
    "\n",
    "# y_test_prediction = pd.DataFrame(test_output, columns=['prediction'])\n",
    "\n",
    "# # Save predictions to a CSV file\n",
    "# y_test_prediction.to_csv('Random_Forest_Answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier with data feature scaling and data imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_sm: 25.0 % of the dataset\n",
      "asd_sm: 25.0 % of the dataset\n",
      "kd_sm: 25.0 % of the dataset\n",
      "rhd_sm: 25.0 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "X = raw_data.drop('state', axis=1)\n",
    "y = raw_data['state']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "def Standard_Scaler (df, col_names):\n",
    "    features = df[col_names]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    df[col_names] = features\n",
    "    \n",
    "    return df\n",
    "\n",
    "col_names = X.columns\n",
    "\n",
    "X_train = Standard_Scaler(X_train, col_names)\n",
    "X_validation = Standard_Scaler(X_validation, col_names)\n",
    "\n",
    "resample = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "\n",
    "X_train_resampled, y_train_resampled = resample.fit_resample(X_train, y_train)\n",
    "\n",
    "print('normal_sm:', round(y_train_resampled.value_counts()[0]/len(y_train_resampled) * 100,2), '% of the dataset')\n",
    "print('asd_sm:', round(y_train_resampled.value_counts()[1]/len(y_train_resampled) * 100,2), '% of the dataset')\n",
    "print('kd_sm:', round(y_train_resampled.value_counts()[2]/len(y_train_resampled) * 100,2), '% of the dataset')\n",
    "print('rhd_sm:', round(y_train_resampled.value_counts()[3]/len(y_train_resampled) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier with data feature scaling and data imbalance handling\n",
      "--------------------------------------------------\n",
      "Random Forest Classifier: Training F1 Score: 0.9723153565754665 | Validation F1 Score: 0.37463320497407626\n"
     ]
    }
   ],
   "source": [
    "clf_RFC = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "clf_RFC.fit(X_train_resampled, y_train_resampled)\n",
    "training_output = clf_RFC.predict(X_train_resampled)\n",
    "training_f1 = f1_score(y_train_resampled, training_output, average='macro')\n",
    "\n",
    "Validation_Output = clf_RFC.predict(X_validation)\n",
    "Validation_f1 = f1_score(y_validation, Validation_Output, average='macro')\n",
    "\n",
    "print('Random Forest Classifier with data feature scaling and data imbalance handling')\n",
    "print('-' * 50)\n",
    "print(f'Random Forest Classifier: Training F1 Score: {training_f1} | Validation F1 Score: {Validation_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier with data feature scaling, data imbalance handling, and hyperparameter tuning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 22:32:38,509] A new study created in memory with name: no-name-0e45bc48-ab43-48fa-a9ce-522205d68df1\n",
      "[I 2024-05-10 22:34:47,437] Trial 0 finished with value: 0.4001788460577376 and parameters: {'n_estimators': 186, 'max_depth': 23}. Best is trial 0 with value: 0.4001788460577376.\n",
      "[I 2024-05-10 22:35:56,010] Trial 1 finished with value: 0.40385845871361675 and parameters: {'n_estimators': 100, 'max_depth': 23}. Best is trial 1 with value: 0.40385845871361675.\n",
      "[I 2024-05-10 22:36:04,341] Trial 2 finished with value: 0.38587179779782577 and parameters: {'n_estimators': 12, 'max_depth': 22}. Best is trial 1 with value: 0.40385845871361675.\n",
      "[I 2024-05-10 22:36:34,232] Trial 3 finished with value: 0.3410991035078023 and parameters: {'n_estimators': 79, 'max_depth': 9}. Best is trial 1 with value: 0.40385845871361675.\n",
      "[I 2024-05-10 22:38:06,455] Trial 4 finished with value: 0.4056778026559231 and parameters: {'n_estimators': 141, 'max_depth': 20}. Best is trial 4 with value: 0.4056778026559231.\n",
      "[I 2024-05-10 22:40:09,933] Trial 5 finished with value: 0.4174892614495892 and parameters: {'n_estimators': 196, 'max_depth': 18}. Best is trial 5 with value: 0.4174892614495892.\n",
      "[I 2024-05-10 22:40:45,882] Trial 6 finished with value: 0.3836444138598805 and parameters: {'n_estimators': 71, 'max_depth': 12}. Best is trial 5 with value: 0.4174892614495892.\n",
      "[I 2024-05-10 22:41:36,646] Trial 7 finished with value: 0.4124035918845365 and parameters: {'n_estimators': 71, 'max_depth': 23}. Best is trial 5 with value: 0.4174892614495892.\n",
      "[I 2024-05-10 22:43:10,887] Trial 8 finished with value: 0.4094556012271244 and parameters: {'n_estimators': 149, 'max_depth': 17}. Best is trial 5 with value: 0.4174892614495892.\n",
      "[I 2024-05-10 22:43:29,368] Trial 9 finished with value: 0.26567686025003817 and parameters: {'n_estimators': 79, 'max_depth': 5}. Best is trial 5 with value: 0.4174892614495892.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.4174892614495892\n",
      "  Params: \n",
      "    n_estimators: 196\n",
      "    max_depth: 18\n"
     ]
    }
   ],
   "source": [
    "def create_objective(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 1, 200)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 25)\n",
    "    \n",
    "        clf_GBC = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        clf_GBC.fit(X_train, y_train)\n",
    "        \n",
    "        Validation_Output = clf_GBC.predict(X_val)\n",
    "        Validation_f1 = f1_score(y_val, Validation_Output, average='macro')\n",
    "        \n",
    "        return Validation_f1\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# Now create the objective function using the closure\n",
    "objective = create_objective(X_train_resampled, y_train_resampled, X_validation, y_validation)\n",
    "\n",
    "# Create and run the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
