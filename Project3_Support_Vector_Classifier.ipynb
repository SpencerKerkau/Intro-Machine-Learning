{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine with no data feature scaling or data imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_sm: 96.83 % of the dataset\n",
      "asd_sm: 1.43 % of the dataset\n",
      "kd_sm: 0.64 % of the dataset\n",
      "rhd_sm: 1.1 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "asd_sm = pd.read_csv('asd_sm.csv')\n",
    "kd_sm = pd.read_csv('kd_sm.csv')\n",
    "normal_sm = pd.read_csv('normal_sm.csv')\n",
    "rhd_sm = pd.read_csv('rhd_sm.csv')\n",
    "\n",
    "normal_sm['state'] = 0\n",
    "asd_sm['state'] = 1\n",
    "kd_sm['state'] = 2\n",
    "rhd_sm['state'] = 3\n",
    "\n",
    "combined_df = pd.concat([normal_sm, asd_sm, kd_sm, rhd_sm], axis=0)\n",
    "\n",
    "print('normal_sm:', round(combined_df['state'].value_counts()[0]/len(combined_df) * 100,2), '% of the dataset')\n",
    "print('asd_sm:', round(combined_df['state'].value_counts()[1]/len(combined_df) * 100,2), '% of the dataset')\n",
    "print('kd_sm:', round(combined_df['state'].value_counts()[2]/len(combined_df) * 100,2), '% of the dataset')\n",
    "print('rhd_sm:', round(combined_df['state'].value_counts()[3]/len(combined_df) * 100,2), '% of the dataset')\n",
    "\n",
    "raw_data = combined_df.copy()\n",
    "raw_data.drop_duplicates(inplace=True)\n",
    "\n",
    "X = raw_data.drop('state', axis=1)\n",
    "y = raw_data['state']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine with no data feature scaling or data imbalance handling\n",
      "--------------------------------------------------\n",
      "SVC With rbg kernel -> Training F1 Score: 0.385302406649829 | Validation F1 Score: 0.30905111425539444\n",
      "SVC With polynomial kernel -> Training F1 Score: 0.48143741705359683 | Validation F1 Score: 0.37950796974053846\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_rbf = svm.SVC(kernel=\"rbf\", decision_function_shape='ovo')\n",
    "clf_rbf.fit(X_train, y_train)\n",
    "training_output = clf_rbf.predict(X_train)\n",
    "training_f1 = f1_score(y_train, training_output, average='macro')\n",
    "\n",
    "validation_output = clf_rbf.predict(X_validation)\n",
    "validation_f1 = f1_score(y_validation, validation_output, average='macro')\n",
    "\n",
    "print('Support Vector Machine with no data feature scaling or data imbalance handling')\n",
    "print('-' * 50)\n",
    "print(f'SVC With rbg kernel -> Training F1 Score: {training_f1} | Validation F1 Score: {validation_f1}')\n",
    "\n",
    "clf_linear = svm.SVC(kernel='poly', decision_function_shape='ovo')\n",
    "clf_linear.fit(X_train, y_train)\n",
    "training_output = clf_linear.predict(X_train)\n",
    "training_f1 = f1_score(y_train, training_output, average='macro')\n",
    "\n",
    "validation_output = clf_linear.predict(X_validation)\n",
    "validation_f1 = f1_score(y_validation, validation_output, average='macro')\n",
    "\n",
    "print(f'SVC With polynomial kernel -> Training F1 Score: {training_f1} | Validation F1 Score: {validation_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine with data feature scaling or data imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_sm: 25.0 % of the dataset\n",
      "asd_sm: 25.0 % of the dataset\n",
      "kd_sm: 25.0 % of the dataset\n",
      "rhd_sm: 25.0 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "X = raw_data.drop('state', axis=1)\n",
    "y = raw_data['state']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "def Standard_Scaler (df, col_names):\n",
    "    features = df[col_names]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    df[col_names] = features\n",
    "    \n",
    "    return df\n",
    "\n",
    "col_names = X.columns\n",
    "\n",
    "X_train = Standard_Scaler(X_train, col_names)\n",
    "X_validation = Standard_Scaler(X_validation, col_names)\n",
    "\n",
    "resample = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "\n",
    "X_train_resampled, y_train_resampled = resample.fit_resample(X_train, y_train)\n",
    "\n",
    "print('normal_sm:', round(y_train_resampled.value_counts()[0]/len(y_train_resampled) * 100,2), '% of the dataset')\n",
    "print('asd_sm:', round(y_train_resampled.value_counts()[1]/len(y_train_resampled) * 100,2), '% of the dataset')\n",
    "print('kd_sm:', round(y_train_resampled.value_counts()[2]/len(y_train_resampled) * 100,2), '% of the dataset')\n",
    "print('rhd_sm:', round(y_train_resampled.value_counts()[3]/len(y_train_resampled) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine with data feature scaling and data imbalance handling\n",
      "--------------------------------------------------\n",
      "SVC With rbg kernel -> Training F1 Score: 0.9951462557831576 | Validation F1 Score: 0.44755383025371037\n",
      "SVC With polynomial kernel -> Training F1 Score: 0.9814887584152926 | Validation F1 Score: 0.4422124874700002\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_rbf = svm.SVC(kernel=\"rbf\", decision_function_shape='ovo')\n",
    "clf_rbf.fit(X_train_resampled, y_train_resampled)\n",
    "training_output = clf_rbf.predict(X_train_resampled)\n",
    "training_f1 = f1_score(y_train_resampled, training_output, average='macro')\n",
    "\n",
    "validation_output = clf_rbf.predict(X_validation)\n",
    "validation_f1 = f1_score(y_validation, validation_output, average='macro')\n",
    "\n",
    "print('Support Vector Machine with data feature scaling and data imbalance handling')\n",
    "print('-' * 50)\n",
    "print(f'SVC With rbg kernel -> Training F1 Score: {training_f1} | Validation F1 Score: {validation_f1}')\n",
    "\n",
    "clf_linear = svm.SVC(kernel='poly', decision_function_shape='ovo')\n",
    "clf_linear.fit(X_train_resampled, y_train_resampled)\n",
    "training_output = clf_linear.predict(X_train_resampled)\n",
    "training_f1 = f1_score(y_train_resampled, training_output, average='macro')\n",
    "\n",
    "validation_output = clf_linear.predict(X_validation)\n",
    "validation_f1 = f1_score(y_validation, validation_output, average='macro')\n",
    "\n",
    "print(f'SVC With polynomial kernel -> Training F1 Score: {training_f1} | Validation F1 Score: {validation_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set F1 Score: 0.4172886724881772\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('future.no_silent_downcasting', True)\n",
    "# Test_Set = pd.read_csv('test_all.csv').copy()\n",
    "\n",
    "# X = Test_Set.drop('state', axis=1)\n",
    "# y = Test_Set['state']\n",
    "\n",
    "# mapping = {\n",
    "#     'normal': 0,\n",
    "#     'asd': 1,\n",
    "#     'kd': 2,\n",
    "#     'rhd': 3\n",
    "# }\n",
    "\n",
    "# y = y.replace(mapping)\n",
    "# y.fillna(0, inplace=True)\n",
    "# y = y.astype(int)\n",
    "\n",
    "# def Standard_Scaler (df, col_names):\n",
    "#     features = df[col_names]\n",
    "#     scaler = StandardScaler().fit(features.values)\n",
    "#     features = scaler.transform(features.values)\n",
    "#     df[col_names] = features\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# col_names = X.columns\n",
    "\n",
    "# X_test = Standard_Scaler(X, col_names)\n",
    "\n",
    "# test_output = clf_rbf.predict(X_test)\n",
    "\n",
    "# test_f1 = f1_score(y, test_output, average='macro')\n",
    "\n",
    "# print(f'Test Set F1 Score: {test_f1}')\n",
    "\n",
    "# y_test_prediction = pd.DataFrame(test_output, columns=['prediction'])\n",
    "\n",
    "# # Now saving it to a CSV file\n",
    "# y_test_prediction.to_csv('Support_Vector_Machine_Answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine With Hyperparameter Tuning Using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 22:33:42,049] A new study created in memory with name: no-name-33ecd94c-a46a-48b6-ac5d-8736250c66d0\n",
      "[I 2024-05-10 22:37:35,667] Trial 0 finished with value: 0.32081381170600853 and parameters: {'C': 0.6945999732582975, 'gamma': 0.01651252323917206}. Best is trial 0 with value: 0.32081381170600853.\n",
      "[I 2024-05-10 22:42:29,035] Trial 1 finished with value: 0.3250001356204364 and parameters: {'C': 0.08272458714053041, 'gamma': 0.027132787351504938}. Best is trial 1 with value: 0.3250001356204364.\n",
      "[I 2024-05-10 22:48:21,805] Trial 2 finished with value: 0.3156987765124126 and parameters: {'C': 0.47466185016705675, 'gamma': 0.021782828673264126}. Best is trial 1 with value: 0.3250001356204364.\n",
      "[I 2024-05-10 23:05:14,334] Trial 3 finished with value: 0.24618101545253862 and parameters: {'C': 0.5338693112034739, 'gamma': 0.11095671852028988}. Best is trial 1 with value: 0.3250001356204364.\n",
      "[I 2024-05-10 23:25:11,779] Trial 4 finished with value: 0.24618101545253862 and parameters: {'C': 0.2953522843271251, 'gamma': 0.3002483927514424}. Best is trial 1 with value: 0.3250001356204364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.3250001356204364\n",
      "  Params: \n",
      "    C: 0.08272458714053041\n",
      "    gamma: 0.027132787351504938\n"
     ]
    }
   ],
   "source": [
    "def create_objective(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        C = trial.suggest_float(\"C\", 1e-2, 1, log=True)\n",
    "        gamma = trial.suggest_float(\"gamma\", 1e-2, 1, log=True)\n",
    "    \n",
    "        clf_rbf = svm.SVC(kernel=\"rbf\", C=C, gamma=gamma, decision_function_shape='ovo')\n",
    "        clf_rbf.fit(X_train, y_train)\n",
    "        \n",
    "        validation_output = clf_rbf.predict(X_val)\n",
    "        validation_f1 = f1_score(y_val, validation_output, average='macro')\n",
    "        \n",
    "        return validation_f1  \n",
    "    \n",
    "    return objective\n",
    "\n",
    "# Now create the objective function using the closure\n",
    "objective = create_objective(X_train_resampled, y_train_resampled, X_validation, y_validation)\n",
    "\n",
    "# Create and run the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
