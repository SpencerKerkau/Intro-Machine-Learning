{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework #2 Problem 1a\n",
    "\n",
    "Please find the confusion matrix and ROC curve below. The training accuracy for the test set was found to be 53% while the test accuracy was found to be 48.77%. This accuracy is lower in comparrison to what was originally found from the test set shown during the project 1 submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING, CLEANING, AND SPLITTING THE DATASET ### \n",
    "\n",
    "# Imported Libraries for splitting data, pandas for loading data, and numpy for basic math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "# Read in data from the csv file\n",
    "Data_File_Path = '/Users/spencerkerkau/Desktop/Coding Projects/EE 445/Project 1/class_test.csv'\n",
    "Patient_Master_csv = pd.read_csv(Data_File_Path)\n",
    "\n",
    "# Create a list holding all the desired feature values from the training data set\n",
    "Feature_Data = Patient_Master_csv[['patient_id', 'patient_age', 'breast_cancer_diagnosis_code', 'family_size', 'income_household_median',\n",
    "                                   'home_ownership', 'housing_units', 'home_value', 'rent_median', 'rent_burden', 'education_less_highschool',\n",
    "                                   'education_highschool', 'education_some_college', 'education_bachelors', 'education_graduate', 'education_college_or_above',\n",
    "                                   'education_stem_degree', 'labor_force_participation', 'unemployment_rate', 'race_white', 'race_black', 'race_asian', \n",
    "                                   'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled', 'limited_english', 'health_uninsured', \n",
    "                                   'veteran', 'Ozone', 'PM25', 'N02', 'DiagPeriodL90D']].copy()\n",
    "\n",
    "# Go through all the training data, convert the selected features to integers, and drop the training data with non integer values\n",
    "for Feature in Feature_Data:\n",
    "    # Converts all feature values for each training data point to integers\n",
    "    Feature_Data[Feature] = pd.to_numeric(Feature_Data[Feature], errors='coerce')\n",
    "    # Drops all training data with non integer feature values\n",
    "    Feature_Data.dropna(subset=[Feature], inplace=True)\n",
    "\n",
    "# Test print to confirm the data looks ok\n",
    "#print(Feature_Data)\n",
    "    \n",
    "# Selecting the features from the feature_data list\n",
    "Features = ['patient_id', 'patient_age', 'breast_cancer_diagnosis_code', 'family_size', 'income_household_median',\n",
    "                                   'home_ownership', 'housing_units', 'home_value', 'rent_median', 'rent_burden', 'education_less_highschool',\n",
    "                                   'education_highschool', 'education_some_college', 'education_bachelors', 'education_graduate', 'education_college_or_above',\n",
    "                                   'education_stem_degree', 'labor_force_participation', 'unemployment_rate', 'race_white', 'race_black', 'race_asian', \n",
    "                                   'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled', 'limited_english', 'health_uninsured', \n",
    "                                   'veteran', 'Ozone', 'PM25', 'N02']\n",
    "\n",
    "# Selecting the target from the feature_data list\n",
    "Target = 'DiagPeriodL90D'\n",
    "\n",
    "# Split the feature and target values\n",
    "X = Feature_Data[Features]\n",
    "y = Feature_Data[Target]\n",
    "\n",
    "# Split the dataset into training set and test set with 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     patient_id  DiagPeriodL90D\n",
      "0      350233.0        0.778718\n",
      "1      544004.0        0.102845\n",
      "2      485773.0        0.725083\n",
      "3      462079.0        0.804789\n",
      "4      760455.0        0.747452\n",
      "..          ...             ...\n",
      "510    427931.0        0.798699\n",
      "511    628957.0        0.748380\n",
      "512    380816.0        0.786856\n",
      "513    358162.0        0.764995\n",
      "514    216674.0        0.791389\n",
      "\n",
      "[515 rows x 2 columns]\n",
      "Training Accuracy: 52.988% | Cross Entropy Training Error: 47.012% \n",
      "Testing Accuracy: 48.777% | Cross Entropy Testing Error: 51.223% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2eadd99d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### FITTING DATA AND CALLING THE LOGISTIC FUNCTION ### \n",
    "\n",
    "# Import scikitlearn library for the logistic regression function, mean squared error loss function, and ROC curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, RocCurveDisplay\n",
    "\n",
    "# Preset the logsitic regression function\n",
    "logisticRegr = LogisticRegression(solver='lbfgs', max_iter = 250)\n",
    "\n",
    "# Fit the logistic function using the training data found by splitting the entire set into a training and test set\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "# Find the probabilities of a diagnosis within the next 90 days for the training and test\n",
    "y_train_probabilities = logisticRegr.predict_proba(X_train)\n",
    "y_test_probabilities = logisticRegr.predict_proba(X_test)\n",
    "\n",
    "# Predict whether the patient received a diagnosis within the next 90 days. Can also be done by comparing the prediction probability\n",
    "# to a threshold of 0.5 but the inbuilt predict function does this for us. Call the function for convenience.\n",
    "y_train_predict = logisticRegr.predict(X_train)\n",
    "y_test_predict = logisticRegr.predict(X_test)\n",
    "\n",
    "# Create a dataframe to store the probabiltity of diagnosis in the next 90 days for each patient\n",
    "Patient_Prediction_DF = pd.DataFrame(columns = ['patient_id', 'DiagPeriodL90D'])\n",
    "\n",
    "# Set two index values\n",
    "DF_Idx = 0\n",
    "X_Idx = 0\n",
    "\n",
    "# Loop through the entire test set and assign the probability for each patient according to their patient id\n",
    "for patient_id in X_test['patient_id']:\n",
    "    Patient_Prediction_DF.loc[DF_Idx] = [patient_id, y_test_probabilities[X_Idx][1]]\n",
    "    DF_Idx += 1\n",
    "    X_Idx += 1\n",
    "\n",
    "# Test print to verify the dataframe is properly storing the patient id and associated diagnosis probability\n",
    "print(Patient_Prediction_DF)\n",
    "\n",
    "# Calculate training and testing error using the log_loss/cross-entropy loss.\n",
    "Training_Error = log_loss(y_train, y_train_probabilities)\n",
    "Testing_Error = log_loss(y_test, y_test_probabilities)\n",
    "\n",
    "print('Training Accuracy: %.3f%% | Cross Entropy Training Error: %.3f%% ' % ((1-Training_Error)*100, Training_Error*100))\n",
    "print('Testing Accuracy: %.3f%% | Cross Entropy Testing Error: %.3f%% ' % ((1-Testing_Error)*100, Testing_Error*100))\n",
    "\n",
    "# Create csv file for submission\n",
    "#Patient_Prediction_DF.to_csv('/Users/spencerkerkau/Desktop/Coding Projects/EE 445/Project 1/kerkaus_submission.csv', index=False)\n",
    "\n",
    "# Plot the ROC Curve given the training and testin data\n",
    "RocCurveDisplay.from_estimator(logisticRegr.fit(X_train, y_train), X_test, y_test)\n",
    "\n",
    "CMD_disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_test_predict))\n",
    "CMD_disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 81.125% | Error: 18.875%\n"
     ]
    }
   ],
   "source": [
    "### Reevaluating the model due to low accuracy ###\n",
    "\n",
    "# Imported libraries to varify model using k folding\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Split entire data set into 10 batches\n",
    "kFold = KFold(n_splits = 10, random_state = 0, shuffle = True)\n",
    "\n",
    "# Set the model to logistic regression\n",
    "logisticRegr = LogisticRegression(solver='lbfgs', max_iter = 250)\n",
    "\n",
    "# Compute the cross validation score using the k folded data set and the logistic regression function\n",
    "results = cross_val_score(logisticRegr, X, y, cv = kFold)\n",
    "\n",
    "# Calculate the accuarcy and error of the entire data set by taking the mean of all the batches\n",
    "print('Overall Accuracy: %.3f%% | Error: %.3f%%' % (results.mean()*100, 100 - results.mean()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework #2 Problem 1b\n",
    "\n",
    "Explain your choice of the number of layers, hidden units, activation function etc.\n",
    "\n",
    "1. Because we need to make a deep neural network (2 hidden layers + output layer), I decided to use the minimum amount of required layers and output layer. I used 200, 100, and 1 as my hidden units. I decided to have a large amount of hidden units in the 1st layer and half it for my second layer. The final layer must be 1 as it is the output layer for binary classification. I experimented a little on the amount of hidden units that could improve performance but ultimately decided to leave it at 200, 100, and 1. For activation functions, I used ReLU for the two hidden layers and sigmoid for the output layer. I used sigmoid as the output layer function as it would squish the output value between 0 and 1 which can be used for thresholding to conduct the classification.\n",
    "\n",
    "Compare the neural net results to the previous results\n",
    "\n",
    "1. When comparing the NN results to the results found from project 1 as well as problem 1a, the NN had a much higher accuracy. Project 1a using linear regression found a testing accuracy of 49.58%. Problem 1a found a testing accuracy of 48.77%. After training and testing, the NN found a test accuracy of roughly 70%. What should be noted though is the NN also had a testing loss of over 2. I'm not 100% sure why this is occurring but some research has led me to believe this can occur due to the binary cross entropy function.\n",
    "\n",
    "Homework #2 Problem 1c\n",
    "\n",
    "1. I wasn't able to run the winners code but I did spend time reading and tyring to understand the winners code/throught process. The biggest differences I can see with the winners code are that they take a great deal in cleaning and categorizing the data. For example, I decided to completely obmit any features that did not have a scalar output but the winner converted every feature to usable values. I also noticed that the winner used several different hyperparameter tuning to try and get the highest possible answer while I used the default hyperparameter values. Personally, I wouldn't really know how to tune the hyperparameters besides heavy test and check process which would take forever to complete. Finally, I noticed that the winner uses boosting and several different classifier techniques to increase his positive classification rate. I only used a simple thresholder to classify the patients.\n",
    "\n",
    "    In genreal, I can see that the winner takes a great amount of time and effort in cleaning and tuning the model which allowed him to squeeze as much performance out of his model as possible and win the contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencerkerkau/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6825 - loss: 0.6262 - val_accuracy: 0.7922 - val_loss: 0.5050\n",
      "Epoch 2/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7959 - loss: 0.5123 - val_accuracy: 0.8000 - val_loss: 0.4804\n",
      "Epoch 3/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.8065 - loss: 0.4805 - val_accuracy: 0.8039 - val_loss: 0.5307\n",
      "Epoch 4/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7948 - loss: 0.4854 - val_accuracy: 0.8078 - val_loss: 0.4813\n",
      "Epoch 5/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8046 - loss: 0.4603 - val_accuracy: 0.8058 - val_loss: 0.4826\n",
      "Epoch 6/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.8221 - loss: 0.4475 - val_accuracy: 0.8019 - val_loss: 0.4911\n",
      "Epoch 7/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.8064 - loss: 0.4523 - val_accuracy: 0.8019 - val_loss: 0.5000\n",
      "Epoch 8/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.8082 - loss: 0.4496 - val_accuracy: 0.7981 - val_loss: 0.5129\n",
      "Epoch 9/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.8090 - loss: 0.4405 - val_accuracy: 0.7981 - val_loss: 0.5342\n",
      "Epoch 10/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.8027 - loss: 0.4470 - val_accuracy: 0.8000 - val_loss: 0.4922\n",
      "Epoch 11/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.8166 - loss: 0.4169 - val_accuracy: 0.7864 - val_loss: 0.5029\n",
      "Epoch 12/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.8055 - loss: 0.4210 - val_accuracy: 0.7903 - val_loss: 0.5266\n",
      "Epoch 13/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.8306 - loss: 0.3951 - val_accuracy: 0.7728 - val_loss: 0.5740\n",
      "Epoch 14/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.8123 - loss: 0.4095 - val_accuracy: 0.7883 - val_loss: 0.5755\n",
      "Epoch 15/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.8082 - loss: 0.4046 - val_accuracy: 0.7670 - val_loss: 0.5826\n",
      "Epoch 16/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.8173 - loss: 0.3902 - val_accuracy: 0.7767 - val_loss: 0.5494\n",
      "Epoch 17/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.8199 - loss: 0.3854 - val_accuracy: 0.7845 - val_loss: 0.5648\n",
      "Epoch 18/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8211 - loss: 0.3653 - val_accuracy: 0.7864 - val_loss: 0.5661\n",
      "Epoch 19/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.3441 - val_accuracy: 0.7806 - val_loss: 0.5870\n",
      "Epoch 20/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.8180 - loss: 0.3540 - val_accuracy: 0.7845 - val_loss: 0.6279\n",
      "Epoch 21/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.8395 - loss: 0.3210 - val_accuracy: 0.7573 - val_loss: 0.6326\n",
      "Epoch 22/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.8214 - loss: 0.3318 - val_accuracy: 0.7689 - val_loss: 0.6955\n",
      "Epoch 23/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.8307 - loss: 0.3308 - val_accuracy: 0.7592 - val_loss: 0.6194\n",
      "Epoch 24/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.8281 - loss: 0.3403 - val_accuracy: 0.7553 - val_loss: 0.6761\n",
      "Epoch 25/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8315 - loss: 0.3259 - val_accuracy: 0.7359 - val_loss: 0.7520\n",
      "Epoch 26/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.8500 - loss: 0.3111 - val_accuracy: 0.7379 - val_loss: 0.8197\n",
      "Epoch 27/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8348 - loss: 0.3084 - val_accuracy: 0.7340 - val_loss: 0.7400\n",
      "Epoch 28/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.8476 - loss: 0.3031 - val_accuracy: 0.7592 - val_loss: 0.7569\n",
      "Epoch 29/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.8462 - loss: 0.3314 - val_accuracy: 0.7476 - val_loss: 0.7597\n",
      "Epoch 30/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.8532 - loss: 0.2988 - val_accuracy: 0.7262 - val_loss: 0.8895\n",
      "Epoch 31/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.8684 - loss: 0.2696 - val_accuracy: 0.7534 - val_loss: 0.7488\n",
      "Epoch 32/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.8770 - loss: 0.2793 - val_accuracy: 0.7612 - val_loss: 0.7919\n",
      "Epoch 33/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8880 - loss: 0.2754 - val_accuracy: 0.7573 - val_loss: 0.8966\n",
      "Epoch 34/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.8825 - loss: 0.2466 - val_accuracy: 0.7437 - val_loss: 0.9421\n",
      "Epoch 35/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.8827 - loss: 0.2577 - val_accuracy: 0.7456 - val_loss: 0.9915\n",
      "Epoch 36/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.8737 - loss: 0.2441 - val_accuracy: 0.6990 - val_loss: 0.9937\n",
      "Epoch 37/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.8890 - loss: 0.2291 - val_accuracy: 0.7515 - val_loss: 1.2190\n",
      "Epoch 38/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.8832 - loss: 0.2355 - val_accuracy: 0.7184 - val_loss: 1.0697\n",
      "Epoch 39/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.8998 - loss: 0.2142 - val_accuracy: 0.6971 - val_loss: 1.1337\n",
      "Epoch 40/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.8825 - loss: 0.2445 - val_accuracy: 0.7282 - val_loss: 1.0855\n",
      "Epoch 41/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.8745 - loss: 0.2556 - val_accuracy: 0.7146 - val_loss: 1.1725\n",
      "Epoch 42/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8973 - loss: 0.2491 - val_accuracy: 0.7029 - val_loss: 0.9959\n",
      "Epoch 43/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.2411 - val_accuracy: 0.7495 - val_loss: 1.1480\n",
      "Epoch 44/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9014 - loss: 0.2176 - val_accuracy: 0.6990 - val_loss: 1.0409\n",
      "Epoch 45/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9035 - loss: 0.2213 - val_accuracy: 0.7379 - val_loss: 1.2510\n",
      "Epoch 46/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9013 - loss: 0.2149 - val_accuracy: 0.6990 - val_loss: 1.1257\n",
      "Epoch 47/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9063 - loss: 0.1952 - val_accuracy: 0.6990 - val_loss: 1.2325\n",
      "Epoch 48/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9197 - loss: 0.1807 - val_accuracy: 0.7107 - val_loss: 1.5109\n",
      "Epoch 49/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9282 - loss: 0.1690 - val_accuracy: 0.7165 - val_loss: 1.3316\n",
      "Epoch 50/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9193 - loss: 0.1735 - val_accuracy: 0.7087 - val_loss: 1.3225\n",
      "Epoch 51/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9098 - loss: 0.1905 - val_accuracy: 0.7087 - val_loss: 1.3226\n",
      "Epoch 52/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9160 - loss: 0.1751 - val_accuracy: 0.7379 - val_loss: 1.3083\n",
      "Epoch 53/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9112 - loss: 0.2010 - val_accuracy: 0.7165 - val_loss: 1.5918\n",
      "Epoch 54/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9033 - loss: 0.2031 - val_accuracy: 0.7126 - val_loss: 1.3130\n",
      "Epoch 55/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9141 - loss: 0.1772 - val_accuracy: 0.7126 - val_loss: 1.3953\n",
      "Epoch 56/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9283 - loss: 0.1604 - val_accuracy: 0.7223 - val_loss: 1.4074\n",
      "Epoch 57/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9401 - loss: 0.1446 - val_accuracy: 0.7359 - val_loss: 1.5635\n",
      "Epoch 58/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9237 - loss: 0.1791 - val_accuracy: 0.7068 - val_loss: 1.3603\n",
      "Epoch 59/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.8939 - loss: 0.2314 - val_accuracy: 0.7146 - val_loss: 1.4062\n",
      "Epoch 60/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9171 - loss: 0.1897 - val_accuracy: 0.7010 - val_loss: 1.4639\n",
      "Epoch 61/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.1629 - val_accuracy: 0.7282 - val_loss: 1.6710\n",
      "Epoch 62/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9326 - loss: 0.1516 - val_accuracy: 0.7126 - val_loss: 1.7067\n",
      "Epoch 63/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9335 - loss: 0.1774 - val_accuracy: 0.7165 - val_loss: 2.0094\n",
      "Epoch 64/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9316 - loss: 0.1654 - val_accuracy: 0.7126 - val_loss: 1.7606\n",
      "Epoch 65/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9312 - loss: 0.1576 - val_accuracy: 0.7495 - val_loss: 1.5121\n",
      "Epoch 66/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9343 - loss: 0.1595 - val_accuracy: 0.7049 - val_loss: 1.8496\n",
      "Epoch 67/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.1406 - val_accuracy: 0.6990 - val_loss: 1.7442\n",
      "Epoch 68/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9392 - loss: 0.1647 - val_accuracy: 0.7068 - val_loss: 1.6418\n",
      "Epoch 69/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.9391 - loss: 0.1435 - val_accuracy: 0.7049 - val_loss: 1.9906\n",
      "Epoch 70/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9503 - loss: 0.1264 - val_accuracy: 0.7126 - val_loss: 1.9026\n",
      "Epoch 71/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.9503 - loss: 0.1163 - val_accuracy: 0.7126 - val_loss: 1.9949\n",
      "Epoch 72/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9623 - loss: 0.1039 - val_accuracy: 0.7243 - val_loss: 2.0708\n",
      "Epoch 73/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9542 - loss: 0.1053 - val_accuracy: 0.7165 - val_loss: 2.1882\n",
      "Epoch 74/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9595 - loss: 0.1145 - val_accuracy: 0.7126 - val_loss: 2.3124\n",
      "Epoch 75/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9444 - loss: 0.1355 - val_accuracy: 0.7204 - val_loss: 2.2696\n",
      "Epoch 76/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9348 - loss: 0.1405 - val_accuracy: 0.7204 - val_loss: 1.9748\n",
      "Epoch 77/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9186 - loss: 0.2126 - val_accuracy: 0.7068 - val_loss: 1.7562\n",
      "Epoch 78/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9162 - loss: 0.1755 - val_accuracy: 0.6874 - val_loss: 1.7721\n",
      "Epoch 79/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.9421 - loss: 0.1478 - val_accuracy: 0.7165 - val_loss: 1.8571\n",
      "Epoch 80/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9471 - loss: 0.1383 - val_accuracy: 0.7204 - val_loss: 1.9610\n",
      "Epoch 81/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.1269 - val_accuracy: 0.7146 - val_loss: 2.0714\n",
      "Epoch 82/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1157 - val_accuracy: 0.7223 - val_loss: 1.8839\n",
      "Epoch 83/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1342 - val_accuracy: 0.7184 - val_loss: 1.9899\n",
      "Epoch 84/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9439 - loss: 0.1232 - val_accuracy: 0.7126 - val_loss: 1.9780\n",
      "Epoch 85/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9562 - loss: 0.1190 - val_accuracy: 0.7165 - val_loss: 2.0768\n",
      "Epoch 86/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9598 - loss: 0.0943 - val_accuracy: 0.7068 - val_loss: 2.1597\n",
      "Epoch 87/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9602 - loss: 0.0992 - val_accuracy: 0.7223 - val_loss: 2.2213\n",
      "Epoch 88/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9572 - loss: 0.1126 - val_accuracy: 0.7146 - val_loss: 2.2018\n",
      "Epoch 89/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9601 - loss: 0.1031 - val_accuracy: 0.7165 - val_loss: 2.3544\n",
      "Epoch 90/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9501 - loss: 0.1043 - val_accuracy: 0.7107 - val_loss: 2.2951\n",
      "Epoch 91/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9652 - loss: 0.0870 - val_accuracy: 0.7107 - val_loss: 2.3230\n",
      "Epoch 92/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9582 - loss: 0.1184 - val_accuracy: 0.7223 - val_loss: 2.3383\n",
      "Epoch 93/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9557 - loss: 0.1044 - val_accuracy: 0.7301 - val_loss: 2.3093\n",
      "Epoch 94/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9519 - loss: 0.1270 - val_accuracy: 0.7204 - val_loss: 2.3813\n",
      "Epoch 95/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9614 - loss: 0.0951 - val_accuracy: 0.7223 - val_loss: 2.4242\n",
      "Epoch 96/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9587 - loss: 0.1025 - val_accuracy: 0.7204 - val_loss: 2.4452\n",
      "Epoch 97/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9653 - loss: 0.0781 - val_accuracy: 0.7223 - val_loss: 2.3699\n",
      "Epoch 98/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9618 - loss: 0.0869 - val_accuracy: 0.7146 - val_loss: 2.3948\n",
      "Epoch 99/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9553 - loss: 0.0974 - val_accuracy: 0.7165 - val_loss: 2.3981\n",
      "Epoch 100/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9641 - loss: 0.0958 - val_accuracy: 0.7068 - val_loss: 2.7288\n",
      "Epoch 101/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9519 - loss: 0.1210 - val_accuracy: 0.7068 - val_loss: 2.2120\n",
      "Epoch 102/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.1574 - val_accuracy: 0.7126 - val_loss: 2.0518\n",
      "Epoch 103/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1958 - val_accuracy: 0.7243 - val_loss: 1.8487\n",
      "Epoch 104/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.1770 - val_accuracy: 0.7320 - val_loss: 2.0639\n",
      "Epoch 105/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.9161 - loss: 0.2105 - val_accuracy: 0.7223 - val_loss: 1.8836\n",
      "Epoch 106/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9309 - loss: 0.1636 - val_accuracy: 0.7379 - val_loss: 2.0838\n",
      "Epoch 107/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9491 - loss: 0.1345 - val_accuracy: 0.7282 - val_loss: 1.9125\n",
      "Epoch 108/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9553 - loss: 0.1184 - val_accuracy: 0.7340 - val_loss: 2.3861\n",
      "Epoch 109/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9507 - loss: 0.1362 - val_accuracy: 0.7165 - val_loss: 2.0912\n",
      "Epoch 110/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9421 - loss: 0.1496 - val_accuracy: 0.7126 - val_loss: 2.0150\n",
      "Epoch 111/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9625 - loss: 0.0964 - val_accuracy: 0.7282 - val_loss: 2.2050\n",
      "Epoch 112/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0899 - val_accuracy: 0.7184 - val_loss: 2.3238\n",
      "Epoch 113/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9668 - loss: 0.0852 - val_accuracy: 0.7204 - val_loss: 2.3126\n",
      "Epoch 114/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9652 - loss: 0.0785 - val_accuracy: 0.7282 - val_loss: 2.4250\n",
      "Epoch 115/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9589 - loss: 0.0975 - val_accuracy: 0.7184 - val_loss: 2.4264\n",
      "Epoch 116/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9637 - loss: 0.0947 - val_accuracy: 0.7146 - val_loss: 2.5905\n",
      "Epoch 117/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9589 - loss: 0.0980 - val_accuracy: 0.7417 - val_loss: 2.4620\n",
      "Epoch 118/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9530 - loss: 0.1015 - val_accuracy: 0.6971 - val_loss: 2.8039\n",
      "Epoch 119/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9496 - loss: 0.1227 - val_accuracy: 0.7243 - val_loss: 2.3994\n",
      "Epoch 120/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9582 - loss: 0.1000 - val_accuracy: 0.7417 - val_loss: 2.3380\n",
      "Epoch 121/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.0760 - val_accuracy: 0.7456 - val_loss: 2.3921\n",
      "Epoch 122/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9643 - loss: 0.0880 - val_accuracy: 0.7262 - val_loss: 2.3529\n",
      "Epoch 123/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9645 - loss: 0.0822 - val_accuracy: 0.7379 - val_loss: 2.4348\n",
      "Epoch 124/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9618 - loss: 0.0906 - val_accuracy: 0.7243 - val_loss: 2.5732\n",
      "Epoch 125/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9607 - loss: 0.0859 - val_accuracy: 0.6971 - val_loss: 2.5530\n",
      "Epoch 126/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9486 - loss: 0.2379 - val_accuracy: 0.7379 - val_loss: 2.4646\n",
      "Epoch 127/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9550 - loss: 0.1328 - val_accuracy: 0.6913 - val_loss: 2.0503\n",
      "Epoch 128/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9375 - loss: 0.1475 - val_accuracy: 0.7223 - val_loss: 1.9689\n",
      "Epoch 129/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9268 - loss: 0.1551 - val_accuracy: 0.7049 - val_loss: 1.9502\n",
      "Epoch 130/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9472 - loss: 0.1395 - val_accuracy: 0.6971 - val_loss: 2.2111\n",
      "Epoch 131/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9457 - loss: 0.1562 - val_accuracy: 0.6893 - val_loss: 2.0512\n",
      "Epoch 132/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9509 - loss: 0.1134 - val_accuracy: 0.7049 - val_loss: 2.1427\n",
      "Epoch 133/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9593 - loss: 0.0968 - val_accuracy: 0.7049 - val_loss: 2.0820\n",
      "Epoch 134/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9561 - loss: 0.1034 - val_accuracy: 0.7087 - val_loss: 2.3706\n",
      "Epoch 135/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9637 - loss: 0.0956 - val_accuracy: 0.7068 - val_loss: 2.3349\n",
      "Epoch 136/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9646 - loss: 0.0945 - val_accuracy: 0.7204 - val_loss: 2.2743\n",
      "Epoch 137/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9696 - loss: 0.0808 - val_accuracy: 0.7165 - val_loss: 2.3851\n",
      "Epoch 138/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9711 - loss: 0.0711 - val_accuracy: 0.7107 - val_loss: 2.4494\n",
      "Epoch 139/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0623 - val_accuracy: 0.6990 - val_loss: 2.4772\n",
      "Epoch 140/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9662 - loss: 0.0719 - val_accuracy: 0.7146 - val_loss: 2.6532\n",
      "Epoch 141/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9735 - loss: 0.0646 - val_accuracy: 0.7126 - val_loss: 2.7137\n",
      "Epoch 142/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9679 - loss: 0.0686 - val_accuracy: 0.7146 - val_loss: 2.8157\n",
      "Epoch 143/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9693 - loss: 0.0679 - val_accuracy: 0.7262 - val_loss: 2.9557\n",
      "Epoch 144/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9701 - loss: 0.0727 - val_accuracy: 0.7107 - val_loss: 2.7923\n",
      "Epoch 145/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9670 - loss: 0.0746 - val_accuracy: 0.7049 - val_loss: 2.8247\n",
      "Epoch 146/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9616 - loss: 0.0892 - val_accuracy: 0.7165 - val_loss: 3.0521\n",
      "Epoch 147/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9630 - loss: 0.0987 - val_accuracy: 0.7204 - val_loss: 2.8351\n",
      "Epoch 148/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9731 - loss: 0.0740 - val_accuracy: 0.7087 - val_loss: 2.8188\n",
      "Epoch 149/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9635 - loss: 0.0812 - val_accuracy: 0.7184 - val_loss: 2.8286\n",
      "Epoch 150/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9601 - loss: 0.0868 - val_accuracy: 0.7204 - val_loss: 2.9352\n",
      "Epoch 151/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9626 - loss: 0.0842 - val_accuracy: 0.7320 - val_loss: 2.7554\n",
      "Epoch 152/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9660 - loss: 0.0783 - val_accuracy: 0.7126 - val_loss: 2.9366\n",
      "Epoch 153/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9682 - loss: 0.0740 - val_accuracy: 0.7282 - val_loss: 3.0799\n",
      "Epoch 154/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0643 - val_accuracy: 0.7126 - val_loss: 2.9318\n",
      "Epoch 155/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.0780 - val_accuracy: 0.7340 - val_loss: 3.0142\n",
      "Epoch 156/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0735 - val_accuracy: 0.7146 - val_loss: 2.9533\n",
      "Epoch 157/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9688 - loss: 0.0694 - val_accuracy: 0.7068 - val_loss: 2.9720\n",
      "Epoch 158/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9672 - loss: 0.0751 - val_accuracy: 0.7165 - val_loss: 2.9564\n",
      "Epoch 159/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9642 - loss: 0.0886 - val_accuracy: 0.7087 - val_loss: 2.8627\n",
      "Epoch 160/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.0771 - val_accuracy: 0.7010 - val_loss: 3.1851\n",
      "Epoch 161/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1006 - val_accuracy: 0.7243 - val_loss: 2.7831\n",
      "Epoch 162/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.9616 - loss: 0.0924 - val_accuracy: 0.7184 - val_loss: 2.8919\n",
      "Epoch 163/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.0954 - val_accuracy: 0.7146 - val_loss: 2.9101\n",
      "Epoch 164/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9597 - loss: 0.1026 - val_accuracy: 0.7029 - val_loss: 3.0019\n",
      "Epoch 165/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9638 - loss: 0.0970 - val_accuracy: 0.6971 - val_loss: 2.7886\n",
      "Epoch 166/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9525 - loss: 0.1319 - val_accuracy: 0.7010 - val_loss: 3.1498\n",
      "Epoch 167/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9305 - loss: 0.2724 - val_accuracy: 0.6971 - val_loss: 2.0743\n",
      "Epoch 168/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8906 - loss: 0.2581 - val_accuracy: 0.7398 - val_loss: 1.9990\n",
      "Epoch 169/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.1710 - val_accuracy: 0.7282 - val_loss: 2.1666\n",
      "Epoch 170/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9533 - loss: 0.1189 - val_accuracy: 0.7359 - val_loss: 2.2633\n",
      "Epoch 171/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9535 - loss: 0.1162 - val_accuracy: 0.7126 - val_loss: 2.2971\n",
      "Epoch 172/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9570 - loss: 0.0955 - val_accuracy: 0.7340 - val_loss: 2.4575\n",
      "Epoch 173/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9655 - loss: 0.0729 - val_accuracy: 0.7204 - val_loss: 2.4666\n",
      "Epoch 174/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9600 - loss: 0.0754 - val_accuracy: 0.7243 - val_loss: 2.6888\n",
      "Epoch 175/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9690 - loss: 0.0675 - val_accuracy: 0.7184 - val_loss: 2.7346\n",
      "Epoch 176/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9736 - loss: 0.0658 - val_accuracy: 0.7184 - val_loss: 2.7784\n",
      "Epoch 177/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9647 - loss: 0.0725 - val_accuracy: 0.7204 - val_loss: 2.9323\n",
      "Epoch 178/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9726 - loss: 0.0654 - val_accuracy: 0.7087 - val_loss: 2.8956\n",
      "Epoch 179/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9730 - loss: 0.0629 - val_accuracy: 0.7243 - val_loss: 2.9361\n",
      "Epoch 180/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9741 - loss: 0.0630 - val_accuracy: 0.7146 - val_loss: 3.1344\n",
      "Epoch 181/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9786 - loss: 0.0549 - val_accuracy: 0.7126 - val_loss: 3.2195\n",
      "Epoch 182/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9719 - loss: 0.0648 - val_accuracy: 0.7340 - val_loss: 3.3057\n",
      "Epoch 183/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9684 - loss: 0.0641 - val_accuracy: 0.7204 - val_loss: 3.1761\n",
      "Epoch 184/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9640 - loss: 0.0810 - val_accuracy: 0.7146 - val_loss: 3.4198\n",
      "Epoch 185/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0682 - val_accuracy: 0.7146 - val_loss: 2.8641\n",
      "Epoch 186/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9733 - loss: 0.0651 - val_accuracy: 0.7165 - val_loss: 2.8951\n",
      "Epoch 187/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9647 - loss: 0.0776 - val_accuracy: 0.6990 - val_loss: 2.9665\n",
      "Epoch 188/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9633 - loss: 0.0798 - val_accuracy: 0.7184 - val_loss: 2.9228\n",
      "Epoch 189/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9590 - loss: 0.1002 - val_accuracy: 0.7146 - val_loss: 2.9708\n",
      "Epoch 190/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0749 - val_accuracy: 0.7204 - val_loss: 3.1541\n",
      "Epoch 191/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.9631 - loss: 0.0803 - val_accuracy: 0.7204 - val_loss: 3.0537\n",
      "Epoch 192/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.0815 - val_accuracy: 0.7184 - val_loss: 3.1822\n",
      "Epoch 193/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.0782 - val_accuracy: 0.7165 - val_loss: 3.1692\n",
      "Epoch 194/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1251 - val_accuracy: 0.7126 - val_loss: 2.8453\n",
      "Epoch 195/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9476 - loss: 0.1095 - val_accuracy: 0.7107 - val_loss: 2.8107\n",
      "Epoch 196/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9682 - loss: 0.0762 - val_accuracy: 0.7204 - val_loss: 3.1376\n",
      "Epoch 197/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9727 - loss: 0.0643 - val_accuracy: 0.7243 - val_loss: 3.2418\n",
      "Epoch 198/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9704 - loss: 0.0628 - val_accuracy: 0.7223 - val_loss: 3.3481\n",
      "Epoch 199/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9694 - loss: 0.0634 - val_accuracy: 0.7282 - val_loss: 3.3542\n",
      "Epoch 200/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9691 - loss: 0.0654 - val_accuracy: 0.7223 - val_loss: 3.4803\n",
      "Epoch 201/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9640 - loss: 0.0806 - val_accuracy: 0.7223 - val_loss: 3.5222\n",
      "Epoch 202/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9642 - loss: 0.0767 - val_accuracy: 0.7126 - val_loss: 3.3770\n",
      "Epoch 203/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.0745 - val_accuracy: 0.6913 - val_loss: 3.1747\n",
      "Epoch 204/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9669 - loss: 0.1249 - val_accuracy: 0.7223 - val_loss: 2.9399\n",
      "Epoch 205/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9382 - loss: 0.1808 - val_accuracy: 0.7049 - val_loss: 2.5927\n",
      "Epoch 206/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9511 - loss: 0.1332 - val_accuracy: 0.7320 - val_loss: 2.7296\n",
      "Epoch 207/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9652 - loss: 0.0789 - val_accuracy: 0.7146 - val_loss: 2.8220\n",
      "Epoch 208/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.0800 - val_accuracy: 0.7223 - val_loss: 2.8705\n",
      "Epoch 209/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9742 - loss: 0.0697 - val_accuracy: 0.7223 - val_loss: 2.8281\n",
      "Epoch 210/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9738 - loss: 0.0629 - val_accuracy: 0.7262 - val_loss: 3.2824\n",
      "Epoch 211/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9646 - loss: 0.0911 - val_accuracy: 0.7359 - val_loss: 2.9441\n",
      "Epoch 212/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9657 - loss: 0.0804 - val_accuracy: 0.7320 - val_loss: 3.0028\n",
      "Epoch 213/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9657 - loss: 0.0750 - val_accuracy: 0.7320 - val_loss: 3.2436\n",
      "Epoch 214/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9702 - loss: 0.0658 - val_accuracy: 0.7282 - val_loss: 3.3234\n",
      "Epoch 215/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0632 - val_accuracy: 0.7340 - val_loss: 3.2112\n",
      "Epoch 216/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9724 - loss: 0.0583 - val_accuracy: 0.7359 - val_loss: 3.2810\n",
      "Epoch 217/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.0740 - val_accuracy: 0.7282 - val_loss: 3.1727\n",
      "Epoch 218/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.9676 - loss: 0.0766 - val_accuracy: 0.7340 - val_loss: 3.1569\n",
      "Epoch 219/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9691 - loss: 0.0658 - val_accuracy: 0.7398 - val_loss: 3.2406\n",
      "Epoch 220/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9787 - loss: 0.0538 - val_accuracy: 0.7340 - val_loss: 3.1829\n",
      "Epoch 221/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9713 - loss: 0.0793 - val_accuracy: 0.7379 - val_loss: 3.1900\n",
      "Epoch 222/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9633 - loss: 0.0922 - val_accuracy: 0.7223 - val_loss: 3.3229\n",
      "Epoch 223/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9516 - loss: 0.0970 - val_accuracy: 0.7320 - val_loss: 3.2572\n",
      "Epoch 224/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9460 - loss: 0.1172 - val_accuracy: 0.7184 - val_loss: 2.7845\n",
      "Epoch 225/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9385 - loss: 0.1511 - val_accuracy: 0.7204 - val_loss: 2.8555\n",
      "Epoch 226/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9501 - loss: 0.1273 - val_accuracy: 0.7204 - val_loss: 2.7468\n",
      "Epoch 227/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9523 - loss: 0.1063 - val_accuracy: 0.7010 - val_loss: 2.9766\n",
      "Epoch 228/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9345 - loss: 0.1662 - val_accuracy: 0.7126 - val_loss: 2.5710\n",
      "Epoch 229/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9445 - loss: 0.1304 - val_accuracy: 0.7184 - val_loss: 2.7364\n",
      "Epoch 230/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9565 - loss: 0.0874 - val_accuracy: 0.7262 - val_loss: 2.8167\n",
      "Epoch 231/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9684 - loss: 0.0772 - val_accuracy: 0.7282 - val_loss: 3.0350\n",
      "Epoch 232/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.0796 - val_accuracy: 0.7301 - val_loss: 3.0201\n",
      "Epoch 233/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9657 - loss: 0.0851 - val_accuracy: 0.7359 - val_loss: 3.3622\n",
      "Epoch 234/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9582 - loss: 0.0887 - val_accuracy: 0.7262 - val_loss: 2.9532\n",
      "Epoch 235/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9720 - loss: 0.0726 - val_accuracy: 0.7359 - val_loss: 3.0009\n",
      "Epoch 236/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9669 - loss: 0.0699 - val_accuracy: 0.7417 - val_loss: 3.1742\n",
      "Epoch 237/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9592 - loss: 0.0860 - val_accuracy: 0.7184 - val_loss: 3.2674\n",
      "Epoch 238/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9650 - loss: 0.0863 - val_accuracy: 0.7359 - val_loss: 3.1556\n",
      "Epoch 239/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9675 - loss: 0.0716 - val_accuracy: 0.7223 - val_loss: 3.4405\n",
      "Epoch 240/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9727 - loss: 0.0644 - val_accuracy: 0.7301 - val_loss: 3.2132\n",
      "Epoch 241/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9733 - loss: 0.0620 - val_accuracy: 0.7398 - val_loss: 3.3551\n",
      "Epoch 242/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9709 - loss: 0.0602 - val_accuracy: 0.7359 - val_loss: 3.4630\n",
      "Epoch 243/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9745 - loss: 0.0574 - val_accuracy: 0.7243 - val_loss: 3.6510\n",
      "Epoch 244/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9681 - loss: 0.0677 - val_accuracy: 0.7262 - val_loss: 3.5043\n",
      "Epoch 245/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9755 - loss: 0.0617 - val_accuracy: 0.7262 - val_loss: 3.6339\n",
      "Epoch 246/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9706 - loss: 0.0611 - val_accuracy: 0.7282 - val_loss: 3.4653\n",
      "Epoch 247/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.0739 - val_accuracy: 0.7184 - val_loss: 3.7213\n",
      "Epoch 248/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9739 - loss: 0.0542 - val_accuracy: 0.7379 - val_loss: 3.8923\n",
      "Epoch 249/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9761 - loss: 0.0548 - val_accuracy: 0.7379 - val_loss: 3.7498\n",
      "Epoch 250/250\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9824 - loss: 0.0435 - val_accuracy: 0.7379 - val_loss: 3.6038\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7027 - loss: 2.7701\n"
     ]
    }
   ],
   "source": [
    "### LOADING, CLEANING, AND SPLITTING THE DATASET ### \n",
    "\n",
    "# Imported Libraries for splitting data, pandas for loading data, and numpy for basic math\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Read in data from the csv file\n",
    "Data_File_Path = '/Users/spencerkerkau/Desktop/Coding Projects/EE 445/Project 1/class_test.csv'\n",
    "Patient_Master_csv = pd.read_csv(Data_File_Path)\n",
    "\n",
    "# Create a list holding all the desired feature values from the training data set\n",
    "Feature_Data = Patient_Master_csv[['patient_id', 'patient_age', 'breast_cancer_diagnosis_code', 'family_size', 'income_household_median',\n",
    "                                   'home_ownership', 'housing_units', 'home_value', 'rent_median', 'rent_burden', 'education_less_highschool',\n",
    "                                   'education_highschool', 'education_some_college', 'education_bachelors', 'education_graduate', 'education_college_or_above',\n",
    "                                   'education_stem_degree', 'labor_force_participation', 'unemployment_rate', 'race_white', 'race_black', 'race_asian', \n",
    "                                   'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled', 'limited_english', 'health_uninsured', \n",
    "                                   'veteran', 'Ozone', 'PM25', 'N02', 'DiagPeriodL90D']].copy()\n",
    "\n",
    "# Go through all the training data, convert the selected features to integers, and drop the training data with non integer values\n",
    "for Feature in Feature_Data:\n",
    "    # Converts all feature values for each training data point to integers\n",
    "    Feature_Data[Feature] = pd.to_numeric(Feature_Data[Feature], errors='coerce')\n",
    "    # Drops all training data with non integer feature values\n",
    "    Feature_Data.dropna(subset=[Feature], inplace=True)\n",
    "\n",
    "# Test print to confirm the data looks ok\n",
    "#print(Feature_Data)\n",
    "    \n",
    "# Selecting the features from the feature_data list\n",
    "Features = ['patient_id', 'patient_age', 'breast_cancer_diagnosis_code', 'family_size', 'income_household_median',\n",
    "                                   'home_ownership', 'housing_units', 'home_value', 'rent_median', 'rent_burden', 'education_less_highschool',\n",
    "                                   'education_highschool', 'education_some_college', 'education_bachelors', 'education_graduate', 'education_college_or_above',\n",
    "                                   'education_stem_degree', 'labor_force_participation', 'unemployment_rate', 'race_white', 'race_black', 'race_asian', \n",
    "                                   'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled', 'limited_english', 'health_uninsured', \n",
    "                                   'veteran', 'Ozone', 'PM25', 'N02']\n",
    "\n",
    "# Selecting the target from the feature_data list\n",
    "Target = 'DiagPeriodL90D'\n",
    "\n",
    "# Split the feature and target values\n",
    "X = Feature_Data[Features]\n",
    "y = Feature_Data[Target]\n",
    "\n",
    "# Split the dataset into training set and test set with 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale and fit the training and test set so for input into the model\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.fit(X_test)\n",
    "\n",
    "# Transform the testing data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)        \n",
    "\n",
    "## Neural Net model function\n",
    "def NN_model():\n",
    "    \n",
    "    # Declare the model with 3 dense layers\n",
    "    model = Sequential([\n",
    "        # 1st layer has 200 hidden units. Input is of size [33,1] due to 33 features from input. ReLU activation function\n",
    "        Dense(200, input_shape=(33,), activation='relu'),\n",
    "        # 2nd layer has 100 hidden units and is fed from the 1st layer. ReLU activation function\n",
    "        Dense(100, activation='relu'),\n",
    "        # Output layer has 1 output and used sigmoid function to squish output between 0 and 1\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Use Adam optimizer with 0.01 learning rate. Loss should be crossentropy instead of MSE\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "model = NN_model()\n",
    "\n",
    "# Convert your DataFrame data to numpy arrays so it fits properly for training\n",
    "X_train_np = np.array(X_train_scaled)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_np, y_train_np, epochs=250, batch_size = 50, verbose=1, validation_split=0.25)\n",
    "\n",
    "# Resize the test data to be fit in to the model\n",
    "X_test_np = np.array(X_test_scaled)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "# Find the accuracy and loss of the test data\n",
    "Loss, Accuracy = model.evaluate(X_test_np, y_test_np, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
